{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 이슈로 인해 데이터를 축소해 실행한다\n",
    "X, y = X[:20000], y[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (20000,)\n",
      "np.newaxis: (20000, 1)\n",
      "np.newaxis: (1, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(f'Original: {y.shape}') # 1차원 label array\n",
    "print(f'np.newaxis: {y[:, np.newaxis].shape}') # 2차원 array로 만들어준다\n",
    "print(f'np.newaxis: {y[np.newaxis, :].shape}') # Transpose하여 행벡터로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.newaxis: 이미 존재하는 어떤 numpy array의 차원을 늘려주는 역할\n",
    "enc.fit(y[:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = enc.transform(y[:,np.newaxis]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = X[:16000], X[16000:18000], X[18000:], Y[:16000], Y[16000:18000], Y[18000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, W):\n",
    "    K = np.size(W, 1)\n",
    "    A = np.exp(X @ W)\n",
    "    # np.diag -> array 형태여야하므로, np.reshape(***, -1)을 통해 1차원 array로 변형시켜준 것\n",
    "    B = np.diag(1 / (np.reshape(A @ np.ones((K,1)), -1))) # 역행렬을 구하는 것을 조금 더 간단하게 만들기 위한 식\n",
    "    Y = B @ A\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass Logistic Regression\n",
    "def compute_cost(X, T, W):\n",
    "    epsilon = 1e-5\n",
    "    N = len(T)\n",
    "    K = np.size(T, 1)\n",
    "    # np.multiply: element-wise multiplication\n",
    "    # Negative log-likelihood식을 행렬곱 형태로 정리한 형태\n",
    "    cost = - (1/N) * np.ones((1,N)) @ (np.multiply(np.log(softmax(X, W) + epsilon), T)) @ np.ones((K,1)) \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "머신러닝 모델의 과적합(Overfitting)을 막는 방법은 다음과 같다.\n",
    "- Batch Normalization(배치정규화)\n",
    "- Weight Regularization(정규화)\n",
    "- Dropout(학습 시 랜덤으로 뉴런의 일부만을 사용)\n",
    "- Early Stopping(오버피팅이 되기 전에 학습을 정지)\n",
    "\n",
    "이 중 Weight Regularization은 L1, L2 Regularization을 사용한다.\n",
    "\n",
    "### L1, L2 Regularization\n",
    "학습을 진행할 때, 학습 데이터의 특성에 따라서 특정 weight의 값이 지나치게 커질 수 있다. 이 때 overfitting이 쉽게 발생하게 된다. 이를 방지하기 위해서 weight의 값을 작게 유지해주기 위한 방법으로 Loss function에 일정한 값을 추가해준다. 이를 통해서 Loss와 Model Complexity를 최소화시키는 방식으로 식이 변형된다.\n",
    "\n",
    "$ minimize(Loss(Data|Model) + Complexity(Model)) $\n",
    "\n",
    "여기서 모델의 복잡도(Complexity)를 계산하기 위해서 weight값의 최소값을 구하는 방식을 사용하는데, L1의 경우 weight의 절대값의 최소값을, L2의 경우는 weight의 제곱합에 대한 최소값을 구한다.\n",
    "\n",
    "여기에 각 Regularization값의 강도를 조절하기 위해 람다 값을 곱해준다. 람다값이 0에 가까울수록 정규화가 적게 이루어져 overfitting이 쉽게 발생하게 된다.\n",
    "$ minimize(Loss(Data|Model) + \\lambda  Complexity(Model)) $\n",
    "\n",
    "이 때, 선형회귀모델에서 L1규제를 주는 것이 Lasso Regression, L2규제를 주는 것을 Ridge Regression이라고 한다. 이 둘을 동싱 사용하는 방식도 사용 가능하다.\n",
    "\n",
    "L1규제의 경우, 가중치 업데이트 시 작은 가중치들은 0에 수렴하게 된다. 따라서 몇 개의 중요한 weight만이 남게 된다. 따라서 소수의 의미 있는 값을 도출(feature selection 효과)해내고 싶은 sparse한 모델의 경우에 적합하게 사용 가능하다. 그러나 L1규제의 경우 미분이 불가능한 영역이 존재하기 때문에, Gradient-base learning에서는 주의하여 사용해야 한다.\n",
    "\n",
    "L2의 경우는 불필요한 feature의 weight를 0에 가깝게 만들 뿐 0으로 만들지는 않는다. 이런 특성으로 인해 L1에 비해서 상대적으로 선형모델의 일반화 능력이 더 뛰어나다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass Logistic Regression with L2 Regularization\n",
    "def L2_compute_cost(X, T, W, lambda_value):\n",
    "    epsilon = 1e-5\n",
    "    N = len(T)\n",
    "    K = np.size(T, 1)\n",
    "    # L2 Regularization을 추가\n",
    "    ridge_reg_term = (1 / N) * (lambda_value / 2) * np.sum(np.square(W))\n",
    "    cost = - (1/N) * np.ones((1,N)) @ (np.multiply(np.log(softmax(X, W) + epsilon), T)) @ np.ones((K,1)) + ridge_reg_term\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):\n",
    "    return np.argmax((X @ W), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini batch\n",
    "def batch_gd(X, T, W, learning_rate, iterations, batch_size):\n",
    "    N = len(T)\n",
    "    cost_history = np.zeros((iterations,1))\n",
    "    shuffled_indices = np.random.permutation(N)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    T_shuffled = T[shuffled_indices]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        j = i % N\n",
    "        X_batch = X_shuffled[j:j+batch_size]\n",
    "        T_batch = T_shuffled[j:j+batch_size]\n",
    "        # batch가 epoch 경계를 넘어가는 경우, 앞 부분으로 채워줌\n",
    "        if X_batch.shape[0] < batch_size:\n",
    "            X_batch = np.vstack((X_batch, X_shuffled[:(batch_size - X_batch.shape[0])]))\n",
    "            T_batch = np.vstack((T_batch, T_shuffled[:(batch_size - T_batch.shape[0])]))\n",
    "        W = W - (learning_rate/batch_size) * (X_batch.T @ (softmax(X_batch, W) - T_batch))\n",
    "        cost_history[i] = compute_cost(X_batch, T_batch, W)\n",
    "        if i % 1000 == 0:\n",
    "            print(cost_history[i][0])\n",
    "\n",
    "    return (cost_history, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch gradient descent with L2 Regularization\n",
    "def L2_batch_gd(X, T, W, learning_rate, iterations, batch_size, lambda_value):\n",
    "    N = len(T)\n",
    "    cost_history = np.zeros((iterations,1))\n",
    "    shuffled_indices = np.random.permutation(N)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    T_shuffled = T[shuffled_indices]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        j = i % N\n",
    "        X_batch = X_shuffled[j:j+batch_size]\n",
    "        T_batch = T_shuffled[j:j+batch_size]\n",
    "        \n",
    "        if X_batch.shape[0] < batch_size:\n",
    "            X_batch = np.vstack((X_batch, X_shuffled[:(batch_size - X_batch.shape[0])]))\n",
    "            T_batch = np.vstack((T_batch, T_shuffled[:(batch_size - T_batch.shape[0])]))\n",
    "        \n",
    "        error = softmax(X_batch, W) - T_batch\n",
    "        # L2 Regularization이 Cost function에 추가되었으므로, Gradient 또한 L2 Reg term의 미분 값이 포함되어야 한다\n",
    "        gradient = ((1 / batch_size) * (X_batch.T @ error)) + (lambda_value * W)\n",
    "        W = W - (learning_rate * gradient)\n",
    "        cost_history[i] = L2_compute_cost(X_batch, T_batch, W, lambda_value)\n",
    "#         if i % 1000 == 0:\n",
    "#             print(cost_history[i][0])\n",
    "\n",
    "    return (cost_history, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost is: 2.3024850979937064 \n",
      "\n",
      "2.2781058397920453\n",
      "0.6440957439045665\n",
      "0.4950422274292434\n",
      "0.3144196482201307\n",
      "0.5700995473398927\n",
      "0.313889265100568\n",
      "0.2790729748229268\n",
      "0.31092182567930615\n",
      "0.3146507381362376\n",
      "0.25294554648986595\n",
      "0.3068798570554068\n",
      "0.33446675532219716\n",
      "0.26829306200060504\n",
      "0.2943049730367556\n",
      "0.23267393299251854\n",
      "0.19377027437887567\n",
      "0.3947743456983794\n",
      "0.32701703116532965\n",
      "0.31710260776970917\n",
      "0.18037625034621996\n",
      "0.49203315952189797\n",
      "0.19477569459452868\n",
      "0.22433469558129784\n",
      "0.2555142504706855\n",
      "0.2531679029670873\n",
      "0.18610515363288616\n",
      "0.23896183341331595\n",
      "0.3169286891552077\n",
      "0.22783713749881893\n",
      "0.24837803955804372\n",
      "0.2053362314969377\n",
      "0.16047932358869932\n",
      "0.3479142492643788\n",
      "0.2918579738455747\n",
      "0.2660212162094761\n",
      "0.15732797071432353\n",
      "0.4823995515629624\n",
      "0.164992785725649\n",
      "0.21452123058385264\n",
      "0.2408870109318988\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones((np.size(X_train, 0),1)),X_train))\n",
    "T = y_train\n",
    "\n",
    "K = np.size(T, 1)\n",
    "M = np.size(X, 1)\n",
    "W = np.zeros((M,K))\n",
    "\n",
    "iterations = 40000\n",
    "learning_rate = 0.01\n",
    "\n",
    "initial_cost = compute_cost(X, T, W)\n",
    "\n",
    "print(\"Initial Cost is: {} \\n\".format(initial_cost[0][0]))\n",
    "\n",
    "(cost_history, W_optimal) = batch_gd(X, T, W, learning_rate, iterations, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost is: 2.3024850979937064 \n",
      "\n",
      "2.279969397003856\n",
      "0.5102137134772081\n",
      "0.3625999265336366\n",
      "0.40698701855948377\n",
      "0.32044333366664746\n",
      "0.2756165209644355\n",
      "0.3848762436818735\n",
      "0.36208797616485366\n",
      "0.3430986652013604\n",
      "0.21848048906660586\n",
      "0.277361972482939\n",
      "0.19522204073878255\n",
      "0.19741469261499575\n",
      "0.22395556166071703\n",
      "0.48259391058829987\n",
      "0.43676029642502473\n",
      "0.3921078345103752\n",
      "0.18599769397910476\n",
      "0.1734229667923922\n",
      "0.27258622412542666\n",
      "0.24349069032197262\n",
      "0.19276928627733347\n",
      "0.3448951253797428\n",
      "0.29501675626003926\n",
      "0.26780346440167613\n",
      "0.17606874561319066\n",
      "0.23229832706847275\n",
      "0.15204424313613246\n",
      "0.17392881645533784\n",
      "0.19135855558644083\n",
      "0.4490819971411461\n",
      "0.39991445470780274\n",
      "0.3654727353768001\n",
      "0.1683911995540845\n",
      "0.155411795241743\n",
      "0.25410652360471453\n",
      "0.21920935766330935\n",
      "0.17933523646201335\n",
      "0.3368626133614661\n",
      "0.2717386791313132\n",
      "0.24454171832841765\n",
      "0.16464042576411064\n",
      "0.21613847407538397\n",
      "0.1395473243920405\n",
      "0.16594843223759295\n",
      "0.18306085966938482\n",
      "0.43499369180910463\n",
      "0.3851983705017569\n",
      "0.35271865294586496\n",
      "0.16133137274382556\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent with L2 Regularization\n",
    "X = np.hstack((np.ones((np.size(X_train, 0),1)),X_train))\n",
    "T = y_train\n",
    "\n",
    "K = np.size(T, 1)\n",
    "M = np.size(X, 1)\n",
    "W = np.zeros((M,K))\n",
    "\n",
    "iterations = 40000\n",
    "learning_rate = 0.01\n",
    "lambda_value = 0.001\n",
    "\n",
    "initial_cost = L2_compute_cost(X, T, W, lambda_value)\n",
    "\n",
    "print(\"Initial Cost is: {} \\n\".format(initial_cost[0][0]))\n",
    "\n",
    "(cost_history_L2, W_optimal_L2) = L2_batch_gd(X, T, W, learning_rate, iterations, 64, lambda_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent with L2 Regularization\n",
    "def get_optimal_weight(X_train, y_train, lambda_value):\n",
    "    X = np.hstack((np.ones((np.size(X_train, 0),1)),X_train))\n",
    "    T = y_train\n",
    "\n",
    "    K = np.size(T, 1)\n",
    "    M = np.size(X, 1)\n",
    "    W = np.zeros((M,K))\n",
    "\n",
    "    iterations = 40000\n",
    "    learning_rate = 0.01\n",
    "\n",
    "#     initial_cost = L2_compute_cost(X, T, W, lambda_value)\n",
    "#     print(\"Initial Cost is: {} \\n\".format(initial_cost[0][0]))\n",
    "\n",
    "    (cost_history_L2, W_optimal_L2) = L2_batch_gd(X, T, W, learning_rate, iterations, 64, lambda_value)\n",
    "    return W_optimal_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "X_ = np.hstack((np.ones((np.size(X_test, 0),1)),X_test))\n",
    "T_ = y_test\n",
    "y_pred = predict(X_, W_optimal)\n",
    "score = float(sum(y_pred == np.argmax(T_, axis=1)))/ float(len(y_test))\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926\n"
     ]
    }
   ],
   "source": [
    "## L2 Accuracy\n",
    "X_ = np.hstack((np.ones((np.size(X_test, 0),1)),X_test))\n",
    "T_ = y_test\n",
    "y_pred = predict(X_, W_optimal_L2)\n",
    "score = float(sum(y_pred == np.argmax(T_, axis=1)))/ float(len(y_test))\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892\n",
      "0.8285\n",
      "0.8765\n",
      "0.8965\n",
      "0.898\n"
     ]
    }
   ],
   "source": [
    "## get optimal L2 lambda value\n",
    "X_ = np.hstack((np.ones((np.size(X_val, 0),1)),X_val))\n",
    "T_ = y_val\n",
    "lambda_values = [0, 0.1, 0.01, 0.001, 0.0001]\n",
    "scores = []\n",
    "\n",
    "for l_value in lambda_values:\n",
    "    W_ = get_optimal_weight(X_train, y_train, l_value)\n",
    "    y_pred = predict(X_, W_)\n",
    "    score = float(sum(y_pred == np.argmax(T_, axis=1)))/ float(len(y_test))\n",
    "    print(score)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
